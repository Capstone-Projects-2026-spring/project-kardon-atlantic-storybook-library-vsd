"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[2557],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var t=i(96540);const s={},r=t.createContext(s);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}},86658:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"system-architecture/algorithms","title":"algorithms","description":"Algorithms","source":"@site/docs/system-architecture/algorithms.md","sourceDirName":"system-architecture","slug":"/system-architecture/algorithms","permalink":"/project-kardon-atlantic-storybook-library-vsd/docs/system-architecture/algorithms","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2026-spring/project-kardon-atlantic-storybook-library-vsd/edit/main/documentation/docs/system-architecture/algorithms.md","tags":[],"version":"current","lastUpdatedBy":"RolandG369","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"docsSidebar","previous":{"title":"Version Control","permalink":"/project-kardon-atlantic-storybook-library-vsd/docs/system-architecture/version-control"},"next":{"title":"Use Case Diagrams","permalink":"/project-kardon-atlantic-storybook-library-vsd/docs/system-architecture/usecase-diagram"}}');var s=i(74848),r=i(28453);const o={sidebar_position:6},a=void 0,c={},l=[{value:"Algorithms",id:"algorithms",level:2},{value:"Object detection",id:"object-detection",level:3},{value:"Canvas annotation",id:"canvas-annotation",level:3},{value:"State Synchronization",id:"state-synchronization",level:3},{value:"Authentication and Security",id:"authentication-and-security",level:3},{value:"Database Query",id:"database-query",level:3},{value:"Neural Network in Text-To-Speech - finish with 11labs",id:"neural-network-in-text-to-speech---finish-with-11labs",level:3},{value:"Audio Playback",id:"audio-playback",level:3}];function d(e){const n={code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"algorithms",children:"Algorithms"}),"\n",(0,s.jsx)(n.h3,{id:"object-detection",children:"Object detection"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Detect clicks on VSD objects"}),"\n",(0,s.jsx)(n.li,{children:"Each object is stored as a region: x coordinate, y coordinate, width, and height"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Click coordinates (x1, y1)"}),"\n",(0,s.jsx)(n.li,{children:"Iterates through VSD objects on current page"}),"\n",(0,s.jsx)(n.li,{children:"Checks if click is inside the object's region"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Given (x,y) as top left corner, w = width, and h = height"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"If x1 >= x and x1 <= x + w and x1 >= y and y1 <= y + h\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then the click was inside the object's region, trigger the text-to-speech"}),"\n",(0,s.jsx)(n.p,{children:"Time complexity = O(n)\nn = number of objects on page"}),"\n",(0,s.jsx)(n.h3,{id:"canvas-annotation",children:"Canvas annotation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"User can create a new object on storybook page"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Mouse click (x1, y1)"}),"\n",(0,s.jsx)(n.li,{children:"Dynamic rectangle preview"}),"\n",(0,s.jsx)(n.li,{children:"Mouse click (x2, y2)"}),"\n",(0,s.jsx)(n.li,{children:"Store region in database\nTime Complexity = O(1)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"state-synchronization",children:"State Synchronization"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"State -> UI -> User Event -> State Update -> Re-render"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Compare previous componentree with new tree"}),"\n",(0,s.jsx)(n.li,{children:"Compute minimal changes"}),"\n",(0,s.jsx)(n.li,{children:"Apply batched document object model (DOM) updates\nTime Complexity = O(n)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"authentication-and-security",children:"Authentication and Security"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Supabase Auth uses bcrypt hashing algorithm\nhash(inputPassword) == storedHash"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Server generates JSON Web Token"}),"\n",(0,s.jsx)(n.li,{children:"Token signed using secret key"}),"\n",(0,s.jsx)(n.li,{children:"Client stores token"}),"\n",(0,s.jsxs)(n.li,{children:["API request that includes ",(0,s.jsx)(n.code,{children:"Authorization: Bearer <JWT>"}),"\nServer takes care of signature validity and expiration timestamp"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"database-query",children:"Database Query"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Relational database indexing"}),"\n",(0,s.jsx)(n.li,{children:"Primary keys: book_id, page_id, and object_id\nQueries are optimized using B-tree indexing\nTime Complexity = O(logn)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"neural-network-in-text-to-speech---finish-with-11labs",children:"Neural Network in Text-To-Speech - finish with 11labs"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The system does not train its own neural network"}),"\n",(0,s.jsx)(n.li,{children:"The system integrates with a pretrained deep learning speech model provided by ElevenLabs"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Text encoding: input text is tokenized and converted into numerical embeddings."}),"\n",(0,s.jsx)(n.li,{children:"Acoustic feature prediction: encoded text is passed through a decoder network to model rhythm."}),"\n",(0,s.jsx)(n.li,{children:"Neural vocoder: converts the previous data into a raw audio waveform."}),"\n",(0,s.jsx)(n.li,{children:"Speaker conditioning: encodes speech characteristics."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The system sends text and voice parameters to ElevenLabs API and receives an audio response."}),"\n",(0,s.jsx)(n.p,{children:"Time Complexity = constant time external API call"}),"\n",(0,s.jsx)(n.h3,{id:"audio-playback",children:"Audio Playback"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"After audio is returned"}),"\n"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Create audio object"}),"\n",(0,s.jsx)(n.li,{children:"Load binary stream"}),"\n",(0,s.jsx)(n.li,{children:"Decode into playable"}),"\n",(0,s.jsx)(n.li,{children:"Play through browser audio\nAsynchronous and non-blocking"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Time Complexity = O(n)"})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);